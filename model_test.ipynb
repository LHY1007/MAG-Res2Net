{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T03:48:02.468135Z",
     "iopub.status.busy": "2023-08-19T03:48:02.467490Z",
     "iopub.status.idle": "2023-08-19T03:48:08.243419Z",
     "shell.execute_reply": "2023-08-19T03:48:08.242388Z",
     "shell.execute_reply.started": "2023-08-19T03:48:02.468100Z"
    },
    "executionInfo": {
     "elapsed": 1902,
     "status": "ok",
     "timestamp": 1676441630948,
     "user": {
      "displayName": "刘涵瑜",
      "userId": "15463888377010770035"
     },
     "user_tz": -480
    },
    "id": "XObB5T3q_SD6",
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-08-19T08:20:09.152390Z",
     "start_time": "2023-08-19T08:20:06.433559500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "from torch.autograd.function import Function\n",
    "import numpy as np\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import time\n",
    "from torch.optim import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from torch.cuda.amp import autocast as autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import randperm\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# 忽略烦人的红色提示\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T03:48:08.245785Z",
     "iopub.status.busy": "2023-08-19T03:48:08.245197Z",
     "iopub.status.idle": "2023-08-19T03:48:08.421558Z",
     "shell.execute_reply": "2023-08-19T03:48:08.420640Z",
     "shell.execute_reply.started": "2023-08-19T03:48:08.245735Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-08-19T08:20:09.246554100Z",
     "start_time": "2023-08-19T08:20:09.153387400Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-19T03:48:08.423189Z",
     "iopub.status.busy": "2023-08-19T03:48:08.422853Z",
     "iopub.status.idle": "2023-08-19T03:48:08.428526Z",
     "shell.execute_reply": "2023-08-19T03:48:08.427571Z",
     "shell.execute_reply.started": "2023-08-19T03:48:08.423157Z"
    },
    "executionInfo": {
     "elapsed": 886,
     "status": "ok",
     "timestamp": 1676441631832,
     "user": {
      "displayName": "刘涵瑜",
      "userId": "15463888377010770035"
     },
     "user_tz": -480
    },
    "id": "a12F3n8bU8uI",
    "outputId": "47e18653-6722-4484-9fb3-7b1ddb41a0b1",
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-08-19T08:20:09.261549900Z",
     "start_time": "2023-08-19T08:20:09.247551900Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x_list = \"C:/Users/Savior/Desktop/wisdm/wisdm/x_train.npy\"\n",
    "train_y_list = \"C:/Users/Savior/Desktop/wisdm/wisdm/y_train.npy\"\n",
    "test_x_list = \"C:/Users/Savior/Desktop/wisdm/wisdm/x_test.npy\"\n",
    "test_y_list = \"C:/Users/Savior/Desktop/wisdm/wisdm/y_test.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T03:48:08.432317Z",
     "iopub.status.busy": "2023-08-19T03:48:08.431704Z",
     "iopub.status.idle": "2023-08-19T03:48:08.448469Z",
     "shell.execute_reply": "2023-08-19T03:48:08.447497Z",
     "shell.execute_reply.started": "2023-08-19T03:48:08.432284Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-08-19T08:20:09.295455800Z",
     "start_time": "2023-08-19T08:20:09.262547400Z"
    }
   },
   "outputs": [],
   "source": [
    "class HAR_BorderlineSMOTE(Data.Dataset):\n",
    "    def __init__(self, filename_x, filename_y):\n",
    "        self.filename_x = filename_x\n",
    "        self.filename_y = filename_y\n",
    "\n",
    "    def HAR_data(self):\n",
    "        \n",
    "        data_x_raw = np.load(self.filename_x)\n",
    "        data_x=data_x_raw\n",
    "        data_y = np.load(self.filename_y)\n",
    "        data_x = torch.tensor(data_x, dtype=torch.float32)\n",
    "        data_y = torch.tensor(data_y, dtype=torch.long)\n",
    "        \n",
    "        train_data, val_data, train_label, val_label = train_test_split(data_x, data_y, test_size=0.2)\n",
    "        smo = BorderlineSMOTE(random_state=42,kind=\"borderline-1\")\n",
    "        n, nx, ny = train_data.shape\n",
    "        train_data = train_data.reshape((n,nx*ny))\n",
    "        train_data, train_label = smo.fit_resample(train_data, train_label)\n",
    "        train_data = train_data.reshape((train_data.shape[0],nx,ny))\n",
    "\n",
    "        train_data=np.transpose(train_data,(0,2,1))\n",
    "        val_data=np.transpose(val_data,(0,2,1))\n",
    "        print(Counter(train_label))\n",
    "        print(\"train_data shape:\",train_data.shape)\n",
    "        print(\"val_data shape:\",val_data.shape)\n",
    "\n",
    "        train_dataset = Data.TensorDataset(\n",
    "            torch.from_numpy(train_data), \n",
    "            torch.from_numpy(train_label))\n",
    "        val_dataset = Data.TensorDataset(val_data, val_label)\n",
    "        return train_dataset,val_dataset\n",
    "\n",
    "class trian_HAR(Data.Dataset):\n",
    "    def __init__(self, filename_x, filename_y):\n",
    "        self.filename_x = filename_x\n",
    "        self.filename_y = filename_y\n",
    "\n",
    "    def HAR_data(self):\n",
    "        data_x_raw = np.load(self.filename_x)\n",
    "\n",
    "        data_x=data_x_raw  \n",
    "        #data_x = np.expand_dims(data_x_raw, 1)\n",
    "        #data_x = np.transpose(data_x,(0,2,1))\n",
    "        data_y = np.load(self.filename_y)\n",
    "        train_data, val_data, train_label, val_label = train_test_split(data_x, data_y, test_size=0.2)\n",
    "        \n",
    "        train_data=np.transpose(train_data,(0,2,1))\n",
    "        val_data=np.transpose(val_data,(0,2,1))\n",
    "        print(\"train_data shape:\",train_data.shape)\n",
    "        print(\"val_data shape:\",val_data.shape)\n",
    "\n",
    "        train_dataset = Data.TensorDataset(torch.from_numpy(train_data), torch.from_numpy(train_label))\n",
    "        val_dataset = Data.TensorDataset(torch.from_numpy(val_data), torch.from_numpy(val_label))\n",
    "        return train_dataset,val_dataset\n",
    "\n",
    "class HAR(Data.Dataset):\n",
    "    def __init__(self, filename_x, filename_y):\n",
    "        self.filename_x = filename_x\n",
    "        self.filename_y = filename_y\n",
    "\n",
    "    def HAR_data(self):\n",
    "        data_x_raw = np.load(self.filename_x)\n",
    "\n",
    "        data_x=data_x_raw  # (N, C, H, W) (7352, 1, 128, 9)\n",
    "        # data_x = np.expand_dims(data_x_raw, 1)\n",
    "        data_y = np.load(self.filename_y)\n",
    "        tr1 = torch.from_numpy(data_x)\n",
    "        tr1 = tr1.permute(0, 2, 1)\n",
    "\n",
    "        torch_dataset = Data.TensorDataset(tr1, torch.from_numpy(data_y))\n",
    "        return torch_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T03:48:08.451899Z",
     "iopub.status.busy": "2023-08-19T03:48:08.451600Z",
     "iopub.status.idle": "2023-08-19T03:48:09.506075Z",
     "shell.execute_reply": "2023-08-19T03:48:09.505110Z",
     "shell.execute_reply.started": "2023-08-19T03:48:08.451875Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-08-19T08:20:09.354686Z",
     "start_time": "2023-08-19T08:20:09.281499400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape: (35139, 3, 90)\n",
      "val_data shape: (8785, 3, 90)\n"
     ]
    }
   ],
   "source": [
    "#数据上采样部分\n",
    "#data_train = HAR(train_x_list, train_y_list)\n",
    "#data_train = HAR_SMOTE(train_x_list, train_y_list)\n",
    "data_train= trian_HAR(train_x_list, train_y_list)\n",
    "train_dataset,val_dataset = data_train.HAR_data()\n",
    "data_test = HAR(test_x_list, test_y_list)\n",
    "test_dataset = data_test.HAR_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-19T03:48:09.507621Z",
     "iopub.status.busy": "2023-08-19T03:48:09.507282Z",
     "iopub.status.idle": "2023-08-19T03:48:09.552470Z",
     "shell.execute_reply": "2023-08-19T03:48:09.551026Z",
     "shell.execute_reply.started": "2023-08-19T03:48:09.507587Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1676441632903,
     "user": {
      "displayName": "刘涵瑜",
      "userId": "15463888377010770035"
     },
     "user_tz": -480
    },
    "id": "Qj4U1DNOBGiE",
    "outputId": "4cf38c5c-6687-4513-b65d-337c5868fd7e",
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-08-19T08:20:09.366655200Z",
     "start_time": "2023-08-19T08:20:09.327372100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用GPU训练中：NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "if(torch.cuda.is_available()):\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"使用GPU训练中：{}\".format(torch.cuda.get_device_name()))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"使用CPU训练\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-19T03:48:09.555467Z",
     "iopub.status.busy": "2023-08-19T03:48:09.554535Z",
     "iopub.status.idle": "2023-08-19T03:48:09.563385Z",
     "shell.execute_reply": "2023-08-19T03:48:09.562414Z",
     "shell.execute_reply.started": "2023-08-19T03:48:09.555432Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-08-19T08:20:09.366655200Z",
     "start_time": "2023-08-19T08:20:09.354686Z"
    }
   },
   "outputs": [],
   "source": [
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Conv1d(channels, channels // reduction, kernel_size=1, padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv1d(channels // reduction, channels, kernel_size=1, padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.avg_pool(input)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return input * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-19T03:48:09.565386Z",
     "iopub.status.busy": "2023-08-19T03:48:09.565036Z",
     "iopub.status.idle": "2023-08-19T03:48:09.597147Z",
     "shell.execute_reply": "2023-08-19T03:48:09.596146Z",
     "shell.execute_reply.started": "2023-08-19T03:48:09.565349Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-08-19T08:20:09.415893300Z",
     "start_time": "2023-08-19T08:20:09.356682500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channel)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None,\n",
    "                 groups=1, mod='SE', width_per_group=64):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        width = int(out_channel * (width_per_group / 64.)) * groups\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channel, out_channels=width,\n",
    "                               kernel_size=1, stride=1, bias=False)  # squeeze channels\n",
    "        self.bn1 = nn.BatchNorm1d(width)\n",
    "        # -----------------------------------------\n",
    "        self.conv2 = nn.Conv1d(in_channels=width, out_channels=width, groups=groups,\n",
    "                               kernel_size=3, stride=stride, bias=False, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(width)\n",
    "        # -----------------------------------------\n",
    "        self.conv3 = nn.Conv1d(in_channels=width, out_channels=out_channel*self.expansion,\n",
    "                               kernel_size=1, stride=1, bias=False)  # unsqueeze channels\n",
    "        self.bn3 = nn.BatchNorm1d(out_channel*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.model = mod\n",
    "        if mod == 'SE':\n",
    "            self.mod = SEModule(self.expansion*out_channel)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.model =='SE':\n",
    "            out = self.mod(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 block,\n",
    "                 blocks_num,\n",
    "                 num_classes=1000,\n",
    "                 include_top=True,\n",
    "                 groups=1,\n",
    "                 mod='SE',\n",
    "                 width_per_group=64):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.include_top = include_top\n",
    "        self.in_channel = 64\n",
    "\n",
    "        self.groups = groups\n",
    "        self.width_per_group = width_per_group\n",
    "\n",
    "        self.conv1 = nn.Conv1d(3, self.in_channel, kernel_size=7, stride=2,\n",
    "                               padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(self.in_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, blocks_num[0], mod=mod)\n",
    "        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2, mod=mod)\n",
    "        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2, mod=mod)\n",
    "        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2, mod=mod)\n",
    "\n",
    "        #self.mapping=conv1(in_planes=1024,out_planes=6)\n",
    "\n",
    "        self.preluip1 = nn.PReLU()\n",
    "\n",
    "\n",
    "        if self.include_top:\n",
    "            self.avgpool = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "            #self.avgpool = nn.AdaptiveAvgPool1d((1, ))  # output size = (1, 1)\n",
    "            self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def _make_layer(self, block, channel, block_num, stride=1, mod='SE'):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(channel * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channel,\n",
    "                            channel,\n",
    "                            downsample=downsample,\n",
    "                            stride=stride,\n",
    "                            groups=self.groups,\n",
    "                            mod=mod,\n",
    "                            width_per_group=self.width_per_group))\n",
    "        self.in_channel = channel * block.expansion\n",
    "\n",
    "        for _ in range(1, block_num):\n",
    "            layers.append(block(self.in_channel,\n",
    "                                channel,\n",
    "                                groups=self.groups,\n",
    "                                mod=mod,\n",
    "                                width_per_group=self.width_per_group))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.to(torch.float32).to(device)\n",
    "        #print(x.size())\n",
    "        x = self.conv1(x)\n",
    "        #print(x.size())\n",
    "        x = self.bn1(x)\n",
    "        #print(x.size())\n",
    "        x = self.relu(x)\n",
    "        #print(x.size())\n",
    "        x = self.maxpool(x)\n",
    "        #print(x.size())\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        #print(x.size())\n",
    "        x = self.layer2(x)\n",
    "        #print(x.size())\n",
    "        x = self.layer3(x)\n",
    "        #print(x.size())\n",
    "        x = self.layer4(x)\n",
    "        #print(x.size())\n",
    "        #         x = torch.flatten(x, 1)\n",
    "        #         print(x.size())\n",
    "        #         x = self.fc(x)\n",
    "        #         print(x.size())\n",
    "\n",
    "\n",
    "        if self.include_top:\n",
    "            x = self.avgpool(x)\n",
    "            #print(x.size())\n",
    "            x = torch.flatten(x, 1)\n",
    "            #print(x.size())\n",
    "            x = self.fc(x)\n",
    "            #print(x.size())\n",
    "\n",
    "\n",
    "        output = x\n",
    "        return output\n",
    "        #return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T03:48:09.601470Z",
     "iopub.status.busy": "2023-08-19T03:48:09.600436Z",
     "iopub.status.idle": "2023-08-19T03:48:09.611660Z",
     "shell.execute_reply": "2023-08-19T03:48:09.610712Z",
     "shell.execute_reply.started": "2023-08-19T03:48:09.601434Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-08-19T08:20:09.427935500Z",
     "start_time": "2023-08-19T08:20:09.390621700Z"
    }
   },
   "outputs": [],
   "source": [
    "def resnet34(num_classes=1000, include_top=True):\n",
    "    # https://download.pytorch.org/models/resnet34-333f7ec4.pth\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)\n",
    "\n",
    "\n",
    "def resnet50(num_classes=1000, include_top=True):\n",
    "    # https://download.pytorch.org/models/resnet50-19c8e357.pth\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)\n",
    "\n",
    "\n",
    "def resnet101(num_classes=1000, include_top=True):\n",
    "    # https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes, include_top=include_top)\n",
    "\n",
    "\n",
    "def resnext50_32x4d(num_classes=1000, include_top=True):\n",
    "    # https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\n",
    "    groups = 32\n",
    "    width_per_group = 4\n",
    "    # return ResNet(Bottleneck, [3, 4, 6, 3],\n",
    "    return ResNet(Bottleneck, [2, 3, 4, 0],\n",
    "                  num_classes=num_classes,\n",
    "                  include_top=include_top,\n",
    "                  groups=groups,\n",
    "                  mod=None,\n",
    "                  width_per_group=width_per_group)\n",
    "\n",
    "\n",
    "def resnext101_32x8d(num_classes=1000, include_top=True):\n",
    "    # https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth\n",
    "    groups = 32\n",
    "    width_per_group = 8\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3],\n",
    "                  num_classes=num_classes,\n",
    "                  include_top=include_top,\n",
    "                  groups=groups,\n",
    "                  mod=None,\n",
    "                  width_per_group=width_per_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-19T03:48:09.617335Z",
     "iopub.status.busy": "2023-08-19T03:48:09.616433Z",
     "iopub.status.idle": "2023-08-19T03:48:09.669756Z",
     "shell.execute_reply": "2023-08-19T03:48:09.668662Z",
     "shell.execute_reply.started": "2023-08-19T03:48:09.617300Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-08-19T08:20:09.465039500Z",
     "start_time": "2023-08-19T08:20:09.403505600Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM_CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes):\n",
    "        super(LSTM_CNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True).to(device)\n",
    "        self.conv1 = nn.Conv1d(in_channels=hidden_dim, out_channels=16, kernel_size=5, stride=1).to(device)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, stride=1).to(device)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, stride=1).to(device)\n",
    "        self.conv4 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, stride=1).to(device)\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(128, 64).to(device)\n",
    "        self.fc2 = nn.Linear(64, num_classes).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = x.permute(0, 2, 1)\n",
    "        #h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        # print(h0.shape)\n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        # print(c0.shape)\n",
    "        #out, _ = self.lstm(x, (h0, c0)).to(device)\n",
    "        out, _ = self.lstm(out.to(device))\n",
    "        # print(out.shape)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out = F.relu(self.conv1(out))\n",
    "        out = F.max_pool1d(out, kernel_size=1, stride=1)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool1d(out, kernel_size=2, stride=1)\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = F.max_pool1d(out, kernel_size=2, stride=1)\n",
    "        out = F.relu(self.conv4(out))\n",
    "        out = F.max_pool1d(out, kernel_size=1, stride=1)\n",
    "        out = self.gap(out).squeeze(-1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "import torch.nn.functional as F\n",
    "class TSE_CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(TSE_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=32, kernel_size=3).to(device)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=128, kernel_size=3).to(device)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3).to(device)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1).to(device)\n",
    "        self.fc1 = nn.Linear(256, 64).to(device)\n",
    "        self.fc2 = nn.Linear(64, num_classes).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32).to(device)\n",
    "        # print(x.type())\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"Conv1 output shape: \", x.shape)\n",
    "        x = F.max_pool1d(x, kernel_size=1)\n",
    "        #print(\"MaxPool1 output shape: \", x.shape)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #print(\"Conv2 output shape: \", x.shape)\n",
    "        x = F.max_pool1d(x, kernel_size=1)\n",
    "        #print(\"MaxPool2 output shape: \", x.shape)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #print(\"Conv3 output shape: \", x.shape)\n",
    "        x = self.pool(x).squeeze(2)\n",
    "        #print(\"AdaptiveMaxPool output shape: \", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"FC1 output shape: \", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"FC2 output shape: \", x.shape)\n",
    "        return x\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(3, 64, 5)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, 5)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, 3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256*17, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, 3, 90)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x) \n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class CNN_GRU(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(CNN_GRU, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=64, kernel_size=1).to(device)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=1).to(device)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=1).to(device)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1).to(device)\n",
    "        self.gru = nn.GRU(input_size=256, hidden_size=hidden_dim, num_layers=1, batch_first=True).to(device)\n",
    "        self.fc1 = nn.Linear(hidden_dim, num_classes).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"Conv1 output shape: \", x.shape)\n",
    "        x = F.max_pool1d(x, kernel_size=2, stride=1)\n",
    "        #print(\"MaxPool1 output shape: \", x.shape)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #print(\"Conv2 output shape: \", x.shape)\n",
    "        x = F.max_pool1d(x, kernel_size=2, stride=1)\n",
    "        #print(\"MaxPool2 output shape: \", x.shape)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #print(\"Conv3 output shape: \", x.shape)\n",
    "        #x = self.pool(x).squeeze(2)\n",
    "        x = self.pool(x)\n",
    "        x = x.permute(0, 2, 1)  # swap batch and sequence dimension\n",
    "        #x = x.squeeze(2).permute(0, 2, 1)\n",
    "        _, h_n = self.gru(x)\n",
    "        x = F.relu(self.fc1(h_n[-1]))\n",
    "        return x\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True).to(device)\n",
    "        self.fc = nn.Linear(hidden_size, output_size).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # 初始化隐藏状态和记忆单元\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # 前向传播\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])  # 取最后一个时间步的输出\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SC_CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(SC_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=64, kernel_size=5).to(device)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5).to(device)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=5).to(device)\n",
    "        self.fc1 = nn.Linear(256, 128).to(device)\n",
    "        self.fc2 = nn.Linear(128, num_classes).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"Conv1 output shape: \", x.shape)\n",
    "        x = F.avg_pool1d(x, kernel_size=3)\n",
    "        #print(\"MaxPool1 output shape: \", x.shape)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #print(\"Conv2 output shape: \", x.shape)\n",
    "        x = F.avg_pool1d(x, kernel_size=3)\n",
    "        #print(\"MaxPool2 output shape: \", x.shape)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #print(\"Conv3 output shape: \", x.shape)\n",
    "        x = F.avg_pool1d(x, kernel_size=3)\n",
    "        # print(x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # print(x.shape)\n",
    "        x = self.fc2(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNNAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(CNNAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=64, kernel_size=3, stride=1).to(device)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1).to(device)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1).to(device)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        ).to(device)\n",
    "        self.fc1 = nn.Linear(256, 128).to(device)\n",
    "        self.fc2 = nn.Linear(128, num_classes).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        attention_weights = self.attention(x.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        x = x * attention_weights\n",
    "        x = self.pool(x).squeeze(2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=64, kernel_size=3, stride=1).to(device)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1).to(device)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1).to(device)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=256, num_heads=8).to(device)\n",
    "        self.fc1 = nn.Linear(256, 128).to(device)\n",
    "        self.fc2 = nn.Linear(128, num_classes).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool1d(x, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.permute(2, 0, 1)  # [swap batch](poe://www.poe.com/_api/key_phrase?phrase=swap%20batch&prompt=Tell%20me%20more%20about%20swap%20batch.) and sequence dimension\n",
    "        x, _ = self.attention(x, x, x)\n",
    "        x = x.permute(1, 2, 0)  # swap back sequence and [batch dimension](poe://www.poe.com/_api/key_phrase?phrase=batch%20dimension&prompt=Tell%20me%20more%20about%20batch%20dimension.)\n",
    "        x = self.pool(x).squeeze(2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-19T03:48:09.671659Z",
     "iopub.status.busy": "2023-08-19T03:48:09.671299Z",
     "iopub.status.idle": "2023-08-19T03:48:09.685075Z",
     "shell.execute_reply": "2023-08-19T03:48:09.684039Z",
     "shell.execute_reply.started": "2023-08-19T03:48:09.671626Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-08-19T08:20:09.465773300Z",
     "start_time": "2023-08-19T08:20:09.450476400Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True).to(device)\n",
    "        self.dropout = nn.Dropout(0.2).to(device)\n",
    "        self.relu = nn.ReLU().to(device)\n",
    "\n",
    "        self.linear1 = nn.Linear(hidden_size*2, input_size).to(device)\n",
    "        self.linear2 = nn.Linear(input_size, hidden_size*2).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        print('x1',x.shape)\n",
    "        residual = x  # 保存输入作为残差连接\n",
    "        output, _ = self.lstm(x)\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        output = self.linear1(output)\n",
    "        #print(output.shape)\n",
    "        #print(residual.shape)\n",
    "        output = self.relu(output + residual)  # 残差连接\n",
    "        output = self.linear2(output)\n",
    "        return output\n",
    "\n",
    "class ResBiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(ResBiLSTM, self).__init__()\n",
    "        self.res_blocks = nn.ModuleList([ResidualBlock(input_size, hidden_size) for _ in range(num_layers)])\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        for block in self.res_blocks:\n",
    "            x = block(x)\n",
    "        output = self.fc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "execution": {
     "iopub.execute_input": "2023-08-19T03:48:09.686917Z",
     "iopub.status.busy": "2023-08-19T03:48:09.686560Z",
     "iopub.status.idle": "2023-08-19T03:48:09.697399Z",
     "shell.execute_reply": "2023-08-19T03:48:09.696495Z",
     "shell.execute_reply.started": "2023-08-19T03:48:09.686885Z"
    },
    "executionInfo": {
     "elapsed": 447,
     "status": "error",
     "timestamp": 1676441755689,
     "user": {
      "displayName": "刘涵瑜",
      "userId": "15463888377010770035"
     },
     "user_tz": -480
    },
    "id": "qe3Nx04LXGFb",
    "outputId": "4c2ed3b0-7b16-495d-fb08-8adb736d975d",
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-08-19T08:20:09.480599800Z",
     "start_time": "2023-08-19T08:20:09.465773300Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, pin_memory=True, shuffle=True,drop_last=True, num_workers=2,)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, pin_memory=True, shuffle=True, num_workers=2,)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=batch_size, pin_memory=True, shuffle=True, num_workers=2,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-19T03:48:09.699288Z",
     "iopub.status.busy": "2023-08-19T03:48:09.698944Z",
     "iopub.status.idle": "2023-08-19T03:48:09.708195Z",
     "shell.execute_reply": "2023-08-19T03:48:09.707186Z",
     "shell.execute_reply.started": "2023-08-19T03:48:09.699255Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-08-19T08:20:09.501577700Z",
     "start_time": "2023-08-19T08:20:09.480599800Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_gmean(predictions, labels):\n",
    "    # 根据预测结果计算TP、FN、TN、FP\n",
    "    # 这里的示例代码假设预测结果是二分类的概率值\n",
    "\n",
    "    y_pred = np.argmax(predictions, axis=0)\n",
    "    y_true = labels\n",
    "\n",
    "    TP = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    FN = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    TN = np.sum((y_pred == 0) & (y_true == 0))\n",
    "    FP = np.sum((y_pred == 1) & (y_true == 0))\n",
    "\n",
    "    # 计算Sensitivity和Specificity\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "\n",
    "    # 计算G-mean\n",
    "    gmean = np.sqrt(sensitivity * specificity)\n",
    "\n",
    "    return gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T03:48:09.710512Z",
     "iopub.status.busy": "2023-08-19T03:48:09.709626Z",
     "iopub.status.idle": "2023-08-19T03:48:09.729246Z",
     "shell.execute_reply": "2023-08-19T03:48:09.728291Z",
     "shell.execute_reply.started": "2023-08-19T03:48:09.710474Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-08-19T08:20:09.512571700Z",
     "start_time": "2023-08-19T08:20:09.497588500Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_dataloader,val_dataloader, num_epochs=50, lr1 = 0.001,batch_size=1024):\n",
    "    # 定义损失函数和优化器.\n",
    "    criterion1 = nn.CrossEntropyLoss()\n",
    "    #criterion2 = CenterLoss(6, 6).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr1)\n",
    "    #optimizer1 = Lion(model.parameters(), lr = lr1, weight_decay=1.0)\n",
    "    #optimizer2 = Lion(criterion2.parameters(), lr = lr2, weight_decay=1.0)\n",
    "\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, pin_memory=True, shuffle=True,drop_last=True, num_workers=2,)\n",
    "    val_dataloader = DataLoader(dataset=val_dataset, batch_size=batch_size, pin_memory=True, shuffle=True, num_workers=2,)\n",
    "\n",
    "    # 定义存储训练和验证结果的列表.\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "\n",
    "\n",
    "    # 定义在验证集上表现最好的模型准确率和损失.\n",
    "    best_val_acc = 0.0\n",
    "    best_val_loss = float('inf')\n",
    "    Best_epoch=0\n",
    "    # 定义存储最佳模型参数的变量.\n",
    "    best_model_params = None\n",
    "    # 开始训练模型.\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        model.train()\n",
    "        for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "            model.train()\n",
    "            # 将输入和标签数据转换为Tensor并放到GPU上（如果有的话）.\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 将梯度清零.\n",
    "            optimizer.zero_grad()\n",
    "            #optimizer1.zero_grad()\n",
    "            #optimizer2.zero_grad()\n",
    "            \n",
    "            # 前向传播.\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # 计算损失和准确率.\n",
    "            loss = criterion1(outputs, labels)#+loss_weight*criterion2(labels,outputs,)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            # 反向传播和更新参数.\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #optimizer1.step()\n",
    "            #optimizer1.step()\n",
    "            # 累计训练损失\n",
    "            train_loss += loss.item()\n",
    "            print(\">\",end=\"\")\n",
    "        # 计算训练准确率和损失.\n",
    "        train_acc = 100.0 * train_correct / train_total\n",
    "        train_loss = train_loss / len(train_dataloader)\n",
    "\n",
    "        # 在验证集上验证模型.\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for i, (inputs, labels) in enumerate(val_dataloader):\n",
    "                # 将输入和标签数据转换为Tensor并放到GPU上（如果有的话）.\n",
    "                model.eval()\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # 前向传播.\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # 计算损失和准确率.\n",
    "                loss = criterion1(outputs, labels)#+loss_weight*criterion2(labels,outputs,)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                # 累计验证损失.\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        \n",
    "        # 计算验证准确率和损失.\n",
    "        val_acc = 100.0 * val_correct / val_total\n",
    "        val_loss = val_loss / len(val_dataloader)\n",
    "        if val_acc > best_val_acc or (val_acc == best_val_acc and val_loss < best_val_loss):\n",
    "            Best_epoch =epoch+1\n",
    "            best_val_acc = val_acc\n",
    "            best_val_loss = val_loss\n",
    "            best_model_params = model.state_dict()\n",
    "        \n",
    "        print()\n",
    "\n",
    "\n",
    "        # 打印训练和验证结果.\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.2f}%, Val Loss: {:.4f}, Val Acc: {:.2f}%'\n",
    "              .format(epoch+1, num_epochs, train_loss, train_acc, val_loss, val_acc))\n",
    "        \n",
    "        # 保存训练和验证结果.\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        val_loss_list.append(val_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "    print(\"The best epoch:\",Best_epoch,\"    Acc:\",best_val_acc)\n",
    "    model.load_state_dict(best_model_params)\n",
    "    # 返回训练和验证结果.\n",
    "    return model.eval(),train_loss_list, train_acc_list, val_loss_list, val_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-19T03:48:09.731820Z",
     "iopub.status.busy": "2023-08-19T03:48:09.731521Z",
     "iopub.status.idle": "2023-08-19T03:48:14.557582Z",
     "shell.execute_reply": "2023-08-19T03:48:14.556543Z",
     "shell.execute_reply.started": "2023-08-19T03:48:09.731788Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-08-19T08:20:09.793588900Z",
     "start_time": "2023-08-19T08:20:09.513545300Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = CNN(num_classes=6).to(device)\n",
    "#model = LSTM(input_size=3, hidden_size=32, num_layers=2, output_size=6)\n",
    "#model = LSTM_CNN(input_dim=3, hidden_dim=32, num_layers=2, num_classes=6)\n",
    "#model = TSE_CNN(input_dim=3, num_classes=6)\n",
    "#model = SC_CNN(input_dim=3, num_classes=6)\n",
    "#model = CNN_GRU(input_dim=3,hidden_dim=32,num_classes=6)\n",
    "#model = CNNAttention(input_dim=3, num_classes=6)\n",
    "#model =  resnet34(num_classes=6, include_top=True).to(device)\n",
    "#model = SelfAttention(input_dim=3, num_classes=6)\n",
    "model =  resnext50_32x4d(num_classes=6, include_top=True).to(device)\n",
    "###model = ResBiLSTM(input_size=3, hidden_size=32, num_layers=6, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-19T03:48:14.559787Z",
     "iopub.status.busy": "2023-08-19T03:48:14.558941Z",
     "iopub.status.idle": "2023-08-19T03:49:12.241585Z",
     "shell.execute_reply": "2023-08-19T03:49:12.239454Z",
     "shell.execute_reply.started": "2023-08-19T03:48:14.559731Z"
    },
    "executionInfo": {
     "elapsed": 6745760,
     "status": "ok",
     "timestamp": 1676441193462,
     "user": {
      "displayName": "刘涵瑜",
      "userId": "15463888377010770035"
     },
     "user_tz": -480
    },
    "id": "vCzfxu3EAqwy",
    "outputId": "3489ed96-850a-4711-e4bf-d57f5741c9dc",
    "trusted": true,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-08-19T08:20:09.793588900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Epoch [1/10], Train Loss: 1.1490, Train Acc: 68.49%, Val Loss: 1.3457, Val Acc: 71.24%\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Epoch [2/10], Train Loss: 0.3703, Train Acc: 86.21%, Val Loss: 0.4234, Val Acc: 85.78%\n"
     ]
    }
   ],
   "source": [
    "#可调参数-部分，另外部分在模型中\n",
    "num_epochs=10\n",
    "lr1 = 0.008\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "model,train_loss_list, train_acc_list, val_loss_list, val_acc_list=train(model, train_dataloader, val_dataloader, num_epochs=num_epochs,lr1 = lr1,batch_size=1024)\n",
    "end_time = time.time()\n",
    "use_time= end_time - start_time\n",
    "print(\"Train and val complete in {:.0f}m {:.0f}s\".format(use_time // 60, use_time % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T03:49:12.243999Z",
     "iopub.status.busy": "2023-08-19T03:49:12.243619Z",
     "iopub.status.idle": "2023-08-19T03:49:12.253454Z",
     "shell.execute_reply": "2023-08-19T03:49:12.252589Z",
     "shell.execute_reply.started": "2023-08-19T03:49:12.243958Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "torch.save({'model': model.state_dict()}, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T03:49:12.255735Z",
     "iopub.status.busy": "2023-08-19T03:49:12.255351Z",
     "iopub.status.idle": "2023-08-19T03:49:12.892380Z",
     "shell.execute_reply": "2023-08-19T03:49:12.891438Z",
     "shell.execute_reply.started": "2023-08-19T03:49:12.255703Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_loss_and_acc(train_loss_list, train_acc_list, val_loss_list, val_acc_list):\n",
    "    # 绘制训练和验证损失\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_loss_list, label='train_loss')\n",
    "    plt.plot(val_loss_list, label='val_loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 绘制训练和验证准确率\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_acc_list, label='train_acc')\n",
    "    plt.plot(val_acc_list, label='val_acc')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_loss_and_acc(train_loss_list, train_acc_list, val_loss_list, val_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T03:49:12.894405Z",
     "iopub.status.busy": "2023-08-19T03:49:12.894030Z",
     "iopub.status.idle": "2023-08-19T03:49:12.906698Z",
     "shell.execute_reply": "2023-08-19T03:49:12.905587Z",
     "shell.execute_reply.started": "2023-08-19T03:49:12.894371Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "def test_final(model, test_dataloader,loss_weight = 0.007):\n",
    "    # 将模型设置为测试模式.\n",
    "    model.eval()\n",
    "\n",
    "       # 定义损失函数和优化器.\n",
    "    criterion1 = nn.CrossEntropyLoss()\n",
    "    #criterion2 = CenterLoss(6, 6).to(device)\n",
    "\n",
    "    loss_weight=0.007\n",
    "    # 在测试集上测试模型.\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    num_classes = 6\n",
    "\n",
    "    conf_matrix = np.zeros((num_classes, num_classes), dtype=int)  # 创建混淆矩阵\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(test_dataloader):\n",
    "            # 将输入和标签数据转换为Tensor并放到GPU上（如果有的话）.\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 前向传播.\n",
    "            outputs = model(inputs)\n",
    "            pre_lab = torch.argmax(outputs, 1)\n",
    "            # 计算损失和准确率.\n",
    "            #loss = criterion1(outputs, labels)\n",
    "            loss = criterion1(outputs, labels)# + loss_weight * criterion2(labels, outputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "\n",
    "            # 累计测试损失.\n",
    "            test_loss += loss.item()\n",
    "            y_true.extend(labels.tolist())\n",
    "            y_pred.extend(pre_lab.tolist())\n",
    "\n",
    "            # 更新混淆矩阵\n",
    "            conf_matrix += confusion_matrix(labels.cpu(), pre_lab.cpu(), labels=range(num_classes))\n",
    "\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    # 计算测试准确率和损失.\n",
    "    test_acc = 100.0 * test_correct / test_total\n",
    "    test_loss = test_loss / len(test_dataloader)\n",
    "\n",
    "    g_mean = np.sqrt(np.diag(conf_matrix) / np.sum(conf_matrix, axis=1))\n",
    "    g_mean = np.mean(g_mean)\n",
    "\n",
    "    # 更新分类报告\n",
    "    report += '\\nG-mean: {:.4f}'.format(g_mean)\n",
    "\n",
    "    # 打印测试结果.\n",
    "    # print('Test Loss: {:.4f}, Test Acc: {:.2f}%'.format(test_loss, test_acc))\n",
    "    print('Test Loss: {:.4f}, Test Acc: {:.2f}%, G-mean: {:.4f}'.format(test_loss, test_acc, g_mean))\n",
    "    print(report)\n",
    "    # 返回测试结果.\n",
    "    return test_loss, test_acc, g_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T03:49:12.908903Z",
     "iopub.status.busy": "2023-08-19T03:49:12.908232Z",
     "iopub.status.idle": "2023-08-19T03:49:13.237158Z",
     "shell.execute_reply": "2023-08-19T03:49:13.236016Z",
     "shell.execute_reply.started": "2023-08-19T03:49:12.908868Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#记录f1-score一列到表格，然后得出总的两个f1参数，以及下方的G-mean直接填写\n",
    "test_loss, test_acc, g_mean=test_final(model, test_dataloader,loss_weight = 0.007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T03:49:13.239934Z",
     "iopub.status.busy": "2023-08-19T03:49:13.239518Z",
     "iopub.status.idle": "2023-08-19T03:49:16.285696Z",
     "shell.execute_reply": "2023-08-19T03:49:16.284671Z",
     "shell.execute_reply.started": "2023-08-19T03:49:13.239892Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "class DrawConfusionMatrix:\n",
    "    def __init__(self, labels_name, normalize=True):\n",
    "        self.normalize = normalize\n",
    "        #将传递的normalize参数赋值给对象的normalize属性，用于指示是否对混淆矩阵进行归一化处理\n",
    "        self.labels_name = labels_name\n",
    "        #用于保存标签名称的列表\n",
    "        self.num_classes = len(labels_name)\n",
    "        #获取labels_name列表的长度，即标签的数量，并将其赋值给对象的num_classes属性\n",
    "        self.matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"float32\")\n",
    "        #创建一个大小为(num_classes, num_classes)的零矩阵，并指定数据类型为float32\n",
    "\n",
    "    def update(self, labels, predicts):\n",
    "        #更新混淆矩阵\n",
    "\n",
    "        for predict, label in zip(labels, predicts):\n",
    "            #真实标签和预测标签\n",
    "            self.matrix[label, predict] += 1\n",
    "            #将每个真实与预测标签的匹配结果加到矩阵中\n",
    "            #将 label 作为行索引，predict 作为列索引，通过 self.matrix[label, predict] 访问到矩阵中的对应元素，并将其加1\n",
    "\n",
    "    def getMatrix(self,normalize=True):\n",
    "        if normalize:\n",
    "            per_sum = self.matrix.sum(axis=1)  # 计算混淆矩阵每行的和，用于百分比计算\n",
    "            for i in range(self.num_classes):\n",
    "                self.matrix[i] =(self.matrix[i] / per_sum[i])   # 百分比转换\n",
    "            self.matrix=np.around(self.matrix, 4)   # 保留2位小数点\n",
    "            self.matrix[np.isnan(self.matrix)] = 0.0  # 可能存在NaN，将其设为0\n",
    "        return self.matrix\n",
    "\n",
    "    def drawMatrix(self):\n",
    "        self.matrix = self.getMatrix(self.normalize)\n",
    "        plt.figure(dpi=480)\n",
    "        plt.imshow(self.matrix, cmap=plt.cm.Blues)  # 仅画出颜色格子，没有值\n",
    "        plt.title(\"WISDM\")  # title\n",
    "        plt.xlabel(\"Predict label\")\n",
    "        plt.ylabel(\"Truth label\")\n",
    "\n",
    "        plt.yticks(range(self.num_classes), self.labels_name)  # y轴标签\n",
    "        plt.xticks(range(self.num_classes), self.labels_name, rotation=30)  # x轴标签\n",
    "        thresh = self.matrix.max() / 2.\n",
    "        for x in range(self.num_classes):\n",
    "            for y in range(self.num_classes):\n",
    "                #value = float(format('%.4f' % self.matrix[y, x]))*100.00 # 数值处理\n",
    "                value = str(format('%.2f' %float(self.matrix[y, x]*100.00)))+'%' # 数值处理\n",
    "                plt.text(x, y, value, verticalalignment='center', horizontalalignment='center',color=\"white\" if self.matrix[y, x] > thresh else \"black\")  # 写值\n",
    "\n",
    "        plt.tight_layout()  # 自动调整子图参数，使之填充整个图像区域\n",
    "\n",
    "        plt.colorbar()  # 色条\n",
    "        plt.savefig('./ConfusionMatrix.png', bbox_inches='tight')  # bbox_inches='tight'可确保标签信息显示全\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "def printMatrix(test_loader, model):\n",
    "    labels_name=[\"Sitting\", \"Upstairs\", \"Downstairs\",\"Walking\", \"Standing\", \"Laying\"]\n",
    "    #labels_name=[\"Walking\", \"Walk upstairs\", \"Walk downstairs\", \"Sitting\", \"Standing\", \"Laying down\"]\n",
    "\n",
    "    drawconfusionmatrix = DrawConfusionMatrix(labels_name=labels_name)  # 实例化\n",
    "    for index, (imgs,labels ) in enumerate(test_loader,1):\n",
    "        labels_pd= model(imgs.float())\n",
    "        predict_np = np.argmax(labels_pd.cpu().detach().numpy(), axis=-1)   # array([0,5,1,6,3,...],dtype=int64)\n",
    "        labels_np = labels.numpy()                                    # array([0,5,0,6,2,...],dtype=int64)\n",
    "        drawconfusionmatrix.update(labels_np, predict_np)   # 将新批次的predict和label更新（保存）\n",
    "\n",
    "    drawconfusionmatrix.drawMatrix()  # 根据所有predict和label，画出混淆矩阵\n",
    "\n",
    "    confusion_mat=drawconfusionmatrix.getMatrix() # 你也可以使用该函数获取混淆矩阵(ndarray)\n",
    "    print(confusion_mat)\n",
    "    \n",
    "def g_mean(y_true, y_pred):\n",
    "    labels_name=[\"Sitting\", \"Upstairs\", \"Downstairs\",\"Walking\", \"Standing\", \"Laying\"]\n",
    "    #labels_name=[\"Walking\", \"Walk upstairs\", \"Walk downstairs\", \"Sitting\", \"Standing\", \"Laying down\"]\n",
    "\n",
    "    drawconfusionmatrix = DrawConfusionMatrix(labels_name=labels_name)  # 实例化\n",
    "    for index, (imgs,labels ) in enumerate(test_dataloader,1):\n",
    "        labels_pd= model(imgs.float())\n",
    "        predict_np = np.argmax(labels_pd.cpu().detach().numpy(), axis=-1)   # array([0,5,1,6,3,...],dtype=int64)\n",
    "        labels_np = labels.numpy()                                    # array([0,5,0,6,2,...],dtype=int64)\n",
    "        drawconfusionmatrix.update(labels_np, predict_np)   # 将新批次的predict和label更新（保存）\n",
    "\n",
    "    drawconfusionmatrix.drawMatrix()  # 根据所有predict和label，画出混淆矩阵\n",
    "\n",
    "    confusion_mat=drawconfusionmatrix.getMatrix() # 你也可以使用该函数获取混淆矩阵(ndarray)\n",
    "    #\n",
    "    #\n",
    "    conf_matrix = confusion_mat\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "\n",
    "    g_mean_score = np.sqrt(specificity * sensitivity)\n",
    "\n",
    "    return g_mean_score\n",
    "\n",
    "print(\"开始绘制混淆矩阵\")\n",
    "printMatrix(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "is_executing": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMpWUdXrzQG9tY0cLvGTnyM",
   "mount_file_id": "1J-AWwz0_nsDFoN9YGs5fN6hvfMQ2D_xx",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "name": "deeplearn",
   "language": "python",
   "display_name": "deeplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
